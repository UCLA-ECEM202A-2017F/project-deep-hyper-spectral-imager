---
layout: default
title: Multimodal Output
description: Multimodal Output
---

## Sequence of Execution

1. First, run the *micarray_recorder.cpp* to capture the sound samples from the sources.
2. Second, run the *convert.py* to convert the raw files generated by matrix creator into hd5 format.
2. Third, run the *basic_beamformer.py* to localise the sound source in 2D.
3. Fourth, capture the Realsense IR and Depth Images manually.
4. Finally run the *hyperspectral.py* with its input arguments being the image locations and the modalities you wish to overlay.
5. Now hover the cursor over the image to see the details of the modalities on the screen.

## Results

* Source Location 1:
![Left-1](/Hyperspectral_Images/Left-1.png)

* Source Location 1: Sound Localization Outputs
![Left-2](/Hyperspectral_Images/Left-3.png)

* Source Location 1: depth
![Left-3](/Hyperspectral_Images/Left-2.png)

* Source Location 2:
![Right-1](/Hyperspectral_Images/Right-2.png)

* Source Location 2: Sound Localization Outputs
![Right-2](/Hyperspectral_Images/Right-1.png)

* Source Location 2: depth
![Right-3](/Hyperspectral_Images/Right-3.png)

* Source Location 3: Sound Localization Outputs
![Right_Down-1](/Hyperspectral_Images/Right_Down-1.png)

* Source Location 3: depth
![Right_Down-2](/Hyperspectral_Images/Right_Down-2.png)
